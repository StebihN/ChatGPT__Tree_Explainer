{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Tree Explainer\n",
    "\n",
    "Some machine learning models are very difficult or impossible to understand. The interpretability of models is a metric that indicates how well we can explain the model's decisions. Model quality and interpretability are typically linked in such a way that higher quality models are more difficult to interpret. In such cases, we use techniques to explain the decisions. One of these is the proxy model, which uses the training data and the decisions of an uninterpretable model and extracts patterns from them. The structure of the proxy model must be transparent, so decision trees are an appropriate choice.\n",
    "\n",
    "However, since decision trees can also be difficult to understand for non-experts, in this volume we will present the operation of the GPTTreeExplainer class, which is designed to easily explain inexplicable models using a proxy decision tree."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing the working environment\n",
    "\n",
    "To prepare the working environment, first import all the libraries you need.\n",
    "\n",
    "- `warnings`: Used to control warnings that may occur during code execution.\n",
    "- `pandas`: Library for data processing and analysis.\n",
    "- `fairlearn.datasets.fetch_adult` and `fetch_acs_income`: Functions to fetch the dataset from which we will train the machine learning models.\n",
    "- `sklearn.model_selection.train_test_split`: Function to split the data into training and test sets.\n",
    "- `sklearn.preprocessing.OneHotEncoder`, `StandardScaler`: `OneHotEncoder` is used to encode categorical features into a binary format, and `StandardScaler` is used to standardize features.\n",
    "- `sklearn.svm.SVC`, `SVR`, `sklearn.ensemble.RandomForestClassifier` and `sklearn.linear_model.LinearRegression`: We will use them to train uninterpretable models.\n",
    "- `sklearn.tree.DecisionTreeRegressor` We will use it as a proxy model in the `GPTTreeExplainer` class.\n",
    "- `GPTTreeExplainer` Import the class whose operation we will demonstrate\n",
    "\n",
    "We will ignore warnings using the `warnings.filterwarnings('ignore')` command to provide better notebook visibility and prevent unnecessary interruptions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from fairlearn.datasets import fetch_adult, fetch_acs_income\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from GPTTreeExplainer import GPTTreeExplainer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification\n",
    "\n",
    "For the purpose of demonstrating the operation of the `GPTTreeExplainer` class in the case of classification, we first import the dataset `fetch_adult`\n",
    "\n",
    "Then we prepare the data for machine learning. We find categorical and numerical features in the data, split the data into training and test sets, and perform encoding of categorical features and normalization of numerical features. Finally, we combine the categorical and numerical features into a single set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = fetch_adult(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "categoric = ['occupation', 'race']\n",
    "numeric = ['age', 'education-num', 'capital-gain', 'capital-loss']\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categoric]), columns=encoder.get_feature_names_out())\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[categoric]), columns=encoder.get_feature_names_out())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train[numeric]), columns=numeric)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test[numeric]), columns=numeric)\n",
    "\n",
    "X_train_preprocessed = pd.concat([X_train_encoded, X_train_scaled], axis=1)\n",
    "X_test_preprocessed = pd.concat([X_test_encoded, X_test_scaled], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Learning inexplicable models: SVC\n",
    "\n",
    "For demonstration purposes, we will use the `SVC` classifier to build a machine learning model that is hard to interpret. First, we perform training on the training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_preprocessed, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Building a proxy tree and obtaining a global interpretation\n",
    "\n",
    "In the code block below, we create an instance of the class `GPTTreeExplainer`, which has the following class variables:\n",
    "- `api_key`: It is needed to access the OpenAI API, through which we retrieve the Chat  GPT explanations.\n",
    "- `model`: Allows the selection of the Chat GPT model to be used to retrieve the explanation. By default, `gpt_3.5_turbo` is used.\n",
    "- `proxy_tree`: Allows the selection of the class that will be used to build the replacement decision tree. It is possible to choose between decision trees from the `sklearn.tree` library. By default, `DecisionTreeClassifier` is used.\n",
    "\n",
    "The `fit` method will train a proxy decision tree on the given training data. The method accepts the following parameters:\n",
    "- `X`: the training set of the data to be used to train the proxy tree.\n",
    "- `model`: the machine learning model for which we would like to receive an explanation\n",
    "\n",
    "In the `fit` method, we first obtain predictions using the given model, which are then used to learn a proxy model together with the given training set. This is then represented in `string` form, which is later used to obtain an explanation from the chatbot\n",
    "\n",
    "\n",
    "The `explain` method is intended to extract the explanation from the GPT chatter. The explanation is designed to give the 5 most important features that influence the model's decisions for each possible class.\n",
    " The method accepts the following parameters:\n",
    "- `tree_model`: Representation of the proxy tree in `string` form, which was obtained in the `fit` method.\n",
    "- `all_data`: Allows to decide whether we want to know other features that affect the model decision. By default, the value is set to `True`.\n",
    "\n",
    "In the `explain` method, we first construct a new OpenAI client instance. Then we check whether it is a classification or a regression model. Based on this, we make a call to the GPT chatter which returns an interpretation of the model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpt_svc = GPTTreeExplainer(\"provide your OpenAI API key here\")\n",
    "proxy_tree_svc = gpt_svc.fit(X_train_preprocessed, svc)\n",
    "explanation = gpt_svc.explain(proxy_tree_svc)\n",
    "print(explanation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Obtaining local interpretation\n",
    "\n",
    "The `GPTTreeExplainer` class can also be used to explain a single decision of a machine learning model. For demonstration, we first use the learned `SVC` model to obtain the prediction. We select one prediction for which we want an explanation. We use the `explain_instace` method to obtain the explanation.\n",
    "\n",
    "The `explain_instance` method takes the following parameters:\n",
    "- `instance`: The data on which the model made its decision.\n",
    "- `decision`: The decision made by the machine learning model\n",
    "- `tree_model`: A representation of the proxy tree in `string` form that was obtained in the `fit` method.\n",
    "- `all_data`: Allows to decide whether we want to know the other features that influenced the decision. By default, the value is set to `True`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(X_test_preprocessed)\n",
    "instance_svc = X_test_preprocessed.iloc[0]\n",
    "instance_svm = instance_svc.to_string()\n",
    "decision_svc= y_pred_svc[0]\n",
    "\n",
    "explain_instance = gpt_svc.explain_instance(instance_svm, decision_svc, proxy_tree_svc)\n",
    "print(explain_instance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression\n",
    "\n",
    "For the purpose of demonstrating how the `GPTTreeExplainer` class works in a regression example, we first import the dataset `fetch_acs_income`\n",
    "\n",
    "Then we prepare the data for machine learning. We find categorical and numerical features in the data, split the data into training and test sets, and perform coding of the categorical features and normalization of the numerical features. Finally, we combine the categorical and numerical features into a single set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_reg = fetch_acs_income(as_frame=True)\n",
    "df_reg = data_reg.frame\n",
    "df_reg = df_reg.iloc[1600000:,:]\n",
    "\n",
    "categoric_reg = ['COW', 'SCHL', 'MAR', 'OCCP', \"POBP\", \"RELP\", \"SEX\", \"RAC1P\"]\n",
    "numeric_reg = ['AGEP', 'WKHP']\n",
    "\n",
    "X_reg = df_reg.drop('PINCP', axis=1)\n",
    "y_reg = df_reg['PINCP']\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2)\n",
    "\n",
    "encoder_two = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train_encoded_reg = pd.DataFrame(encoder_two.fit_transform(X_train_reg[categoric_reg]), columns=encoder_two.get_feature_names_out())\n",
    "X_test_encoded_reg = pd.DataFrame(encoder_two.transform(X_test_reg[categoric_reg]), columns=encoder_two.get_feature_names_out())\n",
    "\n",
    "scaler_two = StandardScaler()\n",
    "X_train_scaled_reg = pd.DataFrame(scaler_two.fit_transform(X_train_reg[numeric_reg]), columns=numeric_reg)\n",
    "X_test_scaled_reg = pd.DataFrame(scaler_two.transform(X_test_reg[numeric_reg]), columns=numeric_reg)\n",
    "\n",
    "X_train_preprocessed_reg = pd.concat([X_train_encoded_reg, X_train_scaled_reg], axis=1)\n",
    "X_test_preprocessed_reg = pd.concat([X_test_encoded_reg, X_test_scaled_reg], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Learning inexplicable models: SVR\n",
    "\n",
    "For demonstration purposes, we will use the `SVR` regressor to build a machine learning model that is hard to interpret. First, we perform the learning on the training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train_preprocessed_reg, y_train_reg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Building a proxy tree and obtaining a global interpretation\n",
    "\n",
    "We will again perform the procedure of obtaining the interpretation, this time on a regression example. Therefore, when creating an instance of the `GPTTreeExplainer` class, we pass `DecisionTreeRegressor` as the `proxy_tree`.\n",
    "\n",
    "The interpretation obtained in the `explain` method in the regression example gives the 5 features that most influence the model's decision for low, medium and high values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpt_svr = GPTTreeExplainer(\"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\", proxy_tree=DecisionTreeRegressor(max_depth=5))\n",
    "proxy_tree_svr = gpt_svr.fit(X_train_preprocessed_reg, svr)\n",
    "explanation = gpt_svr.explain(proxy_tree_svr, all_data=False)\n",
    "print(explanation)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
